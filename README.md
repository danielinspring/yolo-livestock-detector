# YOLO Combined Object Detection Model

Combined YOLO model for detecting both **ride** and **cowtail** objects.

## Project Specifications

- **YOLO Version**: 8 or 11
- **Model Size**: YOLOv8s (small) for optimal performance
- **Input Size**: 640x384
- **Classes**:
  - 0: cowtail
  - 1: ride

## Project Structure

```
.
â”œâ”€â”€ data/                          # Dataset directory
â”‚   â””â”€â”€ project-8-at-2026-01-07-07-09-0780865d/  # Label Studio export
â”œâ”€â”€ scripts/                       # Python scripts
â”‚   â”œâ”€â”€ preprocess_data.py        # Data preprocessing from Label Studio
â”‚   â”œâ”€â”€ train.py                  # Training script
â”‚   â”œâ”€â”€ evaluate.py               # Evaluation script
â”‚   â”œâ”€â”€ compare_models.py         # Compare combined vs separated models
â”‚   â”œâ”€â”€ inference.py              # Video/stream inference
â”‚   â””â”€â”€ auto_label.py             # Auto-labeling tool
â”œâ”€â”€ configs/                       # Configuration files
â”‚   â””â”€â”€ dataset.yaml              # YOLO dataset configuration
â”œâ”€â”€ models/                        # Trained models
â”œâ”€â”€ results/                       # Output results
â”‚   â”œâ”€â”€ train/                    # Training results
â”‚   â”œâ”€â”€ test/                     # Test results
â”‚   â”œâ”€â”€ comparison/               # Model comparison results
â”‚   â””â”€â”€ inference/                # Inference results
â””â”€â”€ requirements.txt               # Python dependencies
```

## Setup

### Quick Setup with Virtual Environment

```bash
# Create virtual environment
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate  # On Mac/Linux
# or
venv\Scripts\activate  # On Windows

# Install dependencies
pip install -r requirements.txt
```

### Traditional Setup

```bash
pip install -r requirements.txt
```

## Web GUI

Launch the web interface for easy interaction with the model:

```bash
# Using the startup script
./run_gui.sh

# Or manually
source venv/bin/activate
streamlit run app.py
```

The GUI will open in your browser at http://localhost:8501

### GUI Features

- **ğŸ“¸ Inference**: Upload images/videos for real-time detection
- **ğŸ·ï¸ Auto-Label**: Batch label new images automatically
- **ğŸ“Š Dataset Info**: View dataset statistics and visualizations

## Command Line Usage

### 1. Preprocess Data
```bash
# Basic preprocessing
python scripts/preprocess_data.py --input data/<your-export-folder>

# With 10% background images (recommended)
python scripts/preprocess_data.py --input data/<your-export-folder> --background-ratio 0.1
```

### 2. Train Model
```bash
python scripts/train.py
```

### 3. Evaluate Model
```bash
python scripts/evaluate.py --weights models/best.pt
```

### 4. Compare Models
```bash
python scripts/compare_models.py --combined models/best.pt --ride models/ride_model.pt --cowtail models/cowtail_model.pt
```

### 5. Run Inference
```bash
# Video file
python scripts/inference.py --source video.mp4 --weights models/best.pt

# Webcam/stream
python scripts/inference.py --source 0 --weights models/best.pt
```

### 6. Auto-Label
```bash
python scripts/auto_label.py --source images/ --weights models/best.pt --output labels/
```

## Notes

- Model trained on 640x384 input resolution
- Optimized for ride and cowtail detection
- Supports both image and video inference
